# ç†è®ºä¸å®ç°çš„å·®è·åˆ†æ

## ğŸ¯ æ ¸å¿ƒé—®é¢˜

å½“å‰ä»£ç è™½ç„¶**åŠŸèƒ½å®Œæ•´**ï¼Œä½†ä¸DGMè®ºæ–‡æ¡†æ¶å­˜åœ¨**ç†è®ºä¸å®ç°çš„é¸¿æ²Ÿ**ã€‚

---

## 1. è¾…åŠ©æ¨¡å‹å¢å¼ºï¼šç†æƒ³ vs ç°å®

### è®ºæ–‡æè¿°
> "é€šè¿‡äººå·¥å®¡æ ¸æˆ–è€…å¼•å…¥ç¬¬ä¸‰æ–¹æ¨¡å‹è¿›è¡Œä¿®æ­£"

**é¢„æœŸ**ï¼šç‹¬ç«‹è®­ç»ƒçš„éªŒè¯æ¨¡å‹ï¼ˆClassifierã€Regressorï¼‰

### å½“å‰å®ç°
```python
# âŒ åªæ˜¯è§„åˆ™åˆ¤æ–­ï¼Œä¸æ˜¯çœŸæ­£çš„MLæ¨¡å‹
def verify_with_classifier(self, samples):
    for sample in samples:
        vtype = int(sample.get("vehicle_type", "1"))
        if 1 <= vtype <= 4:  # ç¡¬ç¼–ç è§„åˆ™
            if axle != "2":
                sample["axle_count"] = "2"
```

### é—®é¢˜
- âŒ æ²¡æœ‰æ¨¡å‹è®­ç»ƒè¿‡ç¨‹
- âŒ æ— æ³•ä»æ•°æ®ä¸­å­¦ä¹ 
- âŒ è§„åˆ™ç¡¬ç¼–ç ï¼Œæ— æ³•æ³›åŒ–

### æ­£ç¡®å®ç°
```python
# âœ… çœŸæ­£çš„è¾…åŠ©æ¨¡å‹
class AuxiliaryClassifier:
    def __init__(self):
        self.model = None
    
    def train(self, training_data, labels):
        """è®­ç»ƒåˆ†ç±»å™¨"""
        from sklearn.ensemble import RandomForestClassifier
        self.model = RandomForestClassifier()
        self.model.fit(training_data, labels)
    
    def verify(self, samples):
        """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹éªŒè¯"""
        features = self._extract_features(samples)
        predictions = self.model.predict(features)
        
        # æ ¹æ®æ¨¡å‹é¢„æµ‹ä¿®æ­£æ•°æ®
        for sample, pred in zip(samples, predictions):
            if pred != sample["expected_label"]:
                sample = self._correct_sample(sample, pred)
        
        return samples
```

---

## 2. SunGenåŒå¾ªç¯ï¼šç®€åŒ–è¿‡åº¦

### è®ºæ–‡æè¿°
> "å†…å¾ªç¯è®­ç»ƒåˆ†ç±»å™¨ï¼Œå¤–å¾ªç¯è°ƒæƒé‡"

**é¢„æœŸ**ï¼š
- å†…å¾ªç¯ï¼šç”¨åŠ æƒæ ·æœ¬è®­ç»ƒåˆ†ç±»å™¨
- å¤–å¾ªç¯ï¼šæ ¹æ®éªŒè¯é›†è°ƒæ•´æ ·æœ¬æƒé‡

### å½“å‰å®ç°
```python
# âŒ å†…å¾ªç¯å˜æˆäº†ç®€å•è¯„åˆ†ï¼Œæ²¡æœ‰è®­ç»ƒè¿‡ç¨‹
def calculate_weights(self, samples, target_dist, validation_samples):
    weights = []
    for sample in samples:
        score, _ = self.sample_filter.evaluate_sample(sample)  # åªè¯„åˆ†
        weights.append(score)
    
    weights = np.array(weights)
    weights = weights / weights.sum()  # å½’ä¸€åŒ–
    return weights
```

### é—®é¢˜
- âŒ æ²¡æœ‰åˆ†ç±»å™¨è®­ç»ƒ
- âŒ æ²¡æœ‰çœŸæ­£çš„åŒå¾ªç¯è¿­ä»£
- âŒ æƒé‡è®¡ç®—åªåŸºäºè§„åˆ™è¯„åˆ†

### æ­£ç¡®å®ç°
```python
# âœ… çœŸæ­£çš„SunGenåŒå¾ªç¯
class SunGenReweighter:
    def calculate_weights(self, train_samples, validation_samples, n_outer=5, n_inner=10):
        """SunGenåŒå¾ªç¯æƒé‡è®¡ç®—
        
        Args:
            train_samples: è®­ç»ƒæ ·æœ¬
            validation_samples: éªŒè¯æ ·æœ¬
            n_outer: å¤–å¾ªç¯è¿­ä»£æ¬¡æ•°
            n_inner: å†…å¾ªç¯è¿­ä»£æ¬¡æ•°
        
        Returns:
            æ ·æœ¬æƒé‡
        """
        n_samples = len(train_samples)
        weights = np.ones(n_samples) / n_samples  # åˆå§‹åŒ–å‡åŒ€æƒé‡
        
        # å¤–å¾ªç¯ï¼šè°ƒæ•´æƒé‡
        for outer_iter in range(n_outer):
            # å†…å¾ªç¯ï¼šç”¨åŠ æƒæ ·æœ¬è®­ç»ƒåˆ†ç±»å™¨
            classifier = self._train_weighted_classifier(
                train_samples, 
                weights, 
                n_iterations=n_inner
            )
            
            # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
            val_predictions = classifier.predict(validation_samples)
            val_loss = self._compute_loss(val_predictions, validation_samples)
            
            # æ ¹æ®éªŒè¯é›†lossè°ƒæ•´æ ·æœ¬æƒé‡
            sample_contributions = self._compute_sample_contributions(
                classifier, 
                train_samples
            )
            weights = self._update_weights(weights, sample_contributions, val_loss)
            
            # å½’ä¸€åŒ–
            weights = weights / weights.sum()
        
        return weights
    
    def _train_weighted_classifier(self, samples, weights, n_iterations):
        """ç”¨åŠ æƒæ ·æœ¬è®­ç»ƒåˆ†ç±»å™¨ï¼ˆå†…å¾ªç¯ï¼‰"""
        from sklearn.ensemble import GradientBoostingClassifier
        
        X = self._extract_features(samples)
        y = self._extract_labels(samples)
        
        classifier = GradientBoostingClassifier(
            n_estimators=n_iterations,
            learning_rate=0.1
        )
        classifier.fit(X, y, sample_weight=weights)
        
        return classifier
```

---

## 3. æ ·æœ¬åˆ†è§£ï¼šç²—ç²’åº¦é—®é¢˜

### è®ºæ–‡æè¿°
> "å°†æ ·æœ¬æ‹†è§£æˆå¤šä¸ªchunks"

**é¢„æœŸ**ï¼šå­—æ®µçº§ç»†ç²’åº¦ï¼ŒåŠ¨æ€å¯è°ƒ

### å½“å‰å®ç°
```python
# âŒ 5ä¸ªç¡¬ç¼–ç ç»„ï¼Œæ— æ³•æ‰©å±•
FIELD_GROUPS = {
    "identity": ["gantry_transaction_id", "pass_id", ...],
    "time": ["transaction_time", "entrance_time"],
    "vehicle": ["vehicle_type", "axle_count", ...],
    "fee": ["pay_fee", "discount_fee", "fee_mileage"],
    "status": ["gantry_type", "media_type", ...]
}

# 5ä¸ªç¡¬ç¼–ç æ–¹æ³•ï¼Œæ–°å¢å­—æ®µéœ€è¦ä¿®æ”¹
def _get_identity_prompt(self, condition): ...
def _get_time_prompt(self, condition, current_sample): ...
def _get_vehicle_prompt(self, condition): ...
def _get_fee_prompt(self, current_sample): ...
def _get_status_prompt(self, condition): ...
```

### é—®é¢˜
- âŒ å­—æ®µç»„ç¡¬ç¼–ç 
- âŒ æ¯ä¸ªç»„éœ€è¦å•ç‹¬å†™promptç”Ÿæˆæ–¹æ³•
- âŒ æ— æ³•æ ¹æ®æ•°æ®ç‰¹ç‚¹åŠ¨æ€è°ƒæ•´åˆ†ç»„
- âŒ æ–°å¢å­—æ®µéœ€è¦ä¿®æ”¹å¤šå¤„ä»£ç 

### æ­£ç¡®å®ç°
```python
# âœ… åŠ¨æ€å¯é…ç½®çš„åˆ†è§£ç­–ç•¥
from typing import List, Dict, Callable
from dataclasses import dataclass

@dataclass
class FieldGroup:
    name: str
    fields: List[str]
    dependencies: List[str]  # ä¾èµ–çš„å…¶ä»–ç»„
    prompt_template: str
    
class ConfigurableSampleDecomposer:
    def __init__(self, schema: Dict):
        self.schema = schema
        self.groups = self._auto_generate_groups()
    
    def _auto_generate_groups(self) -> List[FieldGroup]:
        """æ ¹æ®å­—æ®µä¾èµ–å…³ç³»è‡ªåŠ¨ç”Ÿæˆåˆ†ç»„"""
        dependency_graph = self._analyze_dependencies()
        groups = self._topological_group(dependency_graph)
        return groups
    
    def _analyze_dependencies(self):
        """åˆ†æå­—æ®µé—´çš„ä¾èµ–å…³ç³»"""
        dependencies = {}
        
        for field_name, field_info in self.schema.items():
            # ä»å­—æ®µå…ƒæ•°æ®ä¸­æå–ä¾èµ–
            deps = field_info.get("depends_on", [])
            dependencies[field_name] = deps
        
        return dependencies
    
    def decompose_and_generate(self, condition):
        """åŠ¨æ€åˆ†æ­¥ç”Ÿæˆ"""
        sample = {}
        
        # æŒ‰ä¾èµ–é¡ºåºç”Ÿæˆ
        for group in self.groups:
            # æ£€æŸ¥ä¾èµ–æ˜¯å¦æ»¡è¶³
            if not self._dependencies_satisfied(group, sample):
                raise ValueError(f"Dependencies not satisfied for {group.name}")
            
            # åŠ¨æ€ç”Ÿæˆprompt
            prompt = self._generate_prompt(group, sample, condition)
            
            # ç”Ÿæˆå­—æ®µå€¼
            group_data = self._call_llm(prompt)
            sample.update(group_data)
        
        return sample
    
    def add_field_group(self, group: FieldGroup):
        """åŠ¨æ€æ·»åŠ æ–°çš„å­—æ®µç»„ï¼ˆä¸éœ€è¦ä¿®æ”¹ä»£ç ï¼‰"""
        self.groups.append(group)
        self._recompute_dependencies()
```

**ä½¿ç”¨ç¤ºä¾‹**ï¼š
```python
# å®šä¹‰å­—æ®µschemaï¼ˆå¯ä»¥ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
schema = {
    "gantry_transaction_id": {
        "type": "string",
        "pattern": "^G\\d{14}$",
        "depends_on": []
    },
    "transaction_time": {
        "type": "datetime",
        "depends_on": ["gantry_id"]
    },
    "pay_fee": {
        "type": "integer",
        "depends_on": ["vehicle_type", "fee_mileage"]
    }
}

# è‡ªåŠ¨ç”Ÿæˆåˆ†ç»„å’Œä¾èµ–å…³ç³»
decomposer = ConfigurableSampleDecomposer(schema)
sample = decomposer.decompose_and_generate(condition)
```

---

## 4. ç»“æ„é—®é¢˜ï¼šè‡´å‘½ä¼¤

### é—®é¢˜1ï¼šå¾ªç¯ä¾èµ–

```python
# âŒ å½“å‰ä»£ç 
class DirectEvaluator:
    def __init__(self):
        self.benchmark_evaluator = None  # éœ€è¦è¿è¡Œæ—¶è®¾ç½®
    
    def set_benchmark_evaluator(self, evaluator):
        self.benchmark_evaluator = evaluator

# ä½¿ç”¨
direct = DirectEvaluator()
benchmark = BenchmarkEvaluator(real_samples)
direct.set_benchmark_evaluator(benchmark)  # è€¦åˆæ··ä¹±
```

**æ­£ç¡®å®ç°**ï¼š
```python
# âœ… ä¾èµ–æ³¨å…¥ + æ¥å£éš”ç¦»
from abc import ABC, abstractmethod

class IBenchmarkEvaluator(ABC):
    """Benchmarkè¯„ä¼°å™¨æ¥å£"""
    @abstractmethod
    def evaluate(self, samples: List[Dict]) -> Dict:
        pass

class DirectEvaluator:
    def __init__(self, benchmark: Optional[IBenchmarkEvaluator] = None):
        self.benchmark = benchmark
    
    def evaluate(self, samples):
        faithfulness = self._evaluate_faithfulness(samples)
        diversity = self._evaluate_diversity(samples)
        
        # å¯é€‰çš„benchmarkè¯„ä¼°
        if self.benchmark:
            faithfulness["benchmark"] = self.benchmark.evaluate(samples)
        
        return {
            "faithfulness": faithfulness,
            "diversity": diversity
        }
```

### é—®é¢˜2ï¼šéšå¼å¥‘çº¦

```python
# âŒ learned_statsç»“æ„ä»æœªå®šä¹‰
learned_stats = {}
learned_stats["numerical"]["pay_fee"]["mean"]  # å¯èƒ½KeyError!
```

**æ­£ç¡®å®ç°**ï¼š
```python
# âœ… æ˜ç¡®çš„ç±»å‹å®šä¹‰
from dataclasses import dataclass
from typing import Dict, Optional

@dataclass
class NumericalFieldStats:
    """å•ä¸ªæ•°å€¼å­—æ®µçš„ç»Ÿè®¡ä¿¡æ¯"""
    mean: float
    std: float
    min: float
    max: float
    median: float
    q25: float
    q75: float
    
    def validate(self):
        """éªŒè¯ç»Ÿè®¡é‡çš„åˆç†æ€§"""
        if self.std < 0:
            raise ValueError("std cannot be negative")
        if self.min > self.max:
            raise ValueError("min > max")

@dataclass
class LearnedStatistics:
    """ä»çœŸå®æ•°æ®å­¦ä¹ çš„ç»Ÿè®¡ä¿¡æ¯"""
    numerical: Dict[str, NumericalFieldStats]
    categorical: Dict[str, Dict[str, float]]
    correlations: Dict[str, Dict[str, float]]
    
    def validate(self):
        """éªŒè¯å®Œæ•´æ€§"""
        required_numerical = ["pay_fee", "fee_mileage"]
        for field in required_numerical:
            if field not in self.numerical:
                raise ValueError(f"Missing required field: {field}")
            self.numerical[field].validate()
    
    @classmethod
    def from_samples(cls, samples: List[Dict]) -> 'LearnedStatistics':
        """ä»æ ·æœ¬è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        numerical_stats = cls._compute_numerical_stats(samples)
        categorical_stats = cls._compute_categorical_stats(samples)
        correlations = cls._compute_correlations(samples)
        
        stats = cls(
            numerical=numerical_stats,
            categorical=categorical_stats,
            correlations=correlations
        )
        stats.validate()  # ç¡®ä¿æ•°æ®å®Œæ•´
        
        return stats

# ä½¿ç”¨
learned_stats = LearnedStatistics.from_samples(real_samples)
mean_fee = learned_stats.numerical["pay_fee"].mean  # ç±»å‹å®‰å…¨
```

---

## ğŸ“Š å·®è·çº§åˆ«æ€»ç»“

| åŠŸèƒ½æ¨¡å— | è®ºæ–‡è¦æ±‚ | å½“å‰å®ç° | å·®è· | å½±å“ |
|---------|---------|---------|------|------|
| **è¾…åŠ©æ¨¡å‹å¢å¼º** | ç‹¬ç«‹MLæ¨¡å‹ | è§„åˆ™åˆ¤æ–­ | ğŸ”´ ä¸¥é‡ | æ— æ³•ä»æ•°æ®å­¦ä¹  |
| **SunGenåŒå¾ªç¯** | è®­ç»ƒåˆ†ç±»å™¨+è°ƒæƒé‡ | ç®€å•è¯„åˆ† | ğŸ”´ ä¸¥é‡ | æƒé‡è´¨é‡å·® |
| **æ ·æœ¬åˆ†è§£** | åŠ¨æ€å­—æ®µçº§ | 5ä¸ªç¡¬ç¼–ç ç»„ | ğŸŸ¡ ä¸­ç­‰ | æ‰©å±•æ€§å·® |
| **å¾ªç¯ä¾èµ–** | æ¸…æ™°åˆ†å±‚ | è¿è¡Œæ—¶æ³¨å…¥ | ğŸ”´ ä¸¥é‡ | ç»´æŠ¤å›°éš¾ |
| **æ•°æ®å¥‘çº¦** | æ˜ç¡®ç±»å‹ | éšå¼å­—å…¸ | ğŸŸ¡ ä¸­ç­‰ | å®¹æ˜“KeyError |

---

## ğŸ› ï¸ ä¿®å¤è·¯çº¿å›¾

### Phase 1: ä¿®å¤ç»“æ„é—®é¢˜ï¼ˆ1å‘¨ï¼‰
1. å®šä¹‰æ˜ç¡®çš„æ•°æ®å¥‘çº¦ï¼ˆdataclassï¼‰
2. æ¶ˆé™¤å¾ªç¯ä¾èµ–ï¼ˆä¾èµ–æ³¨å…¥ï¼‰
3. æ·»åŠ æ¥å£å®šä¹‰ï¼ˆABCï¼‰

### Phase 2: å®ç°çœŸæ­£çš„è¾…åŠ©æ¨¡å‹ï¼ˆ2å‘¨ï¼‰
1. è®­ç»ƒè½¦è¾†åˆ†ç±»å™¨
2. è®­ç»ƒè´¹ç”¨å›å½’å™¨
3. é›†æˆåˆ°å¢å¼ºæµç¨‹

### Phase 3: å®ç°SunGenåŒå¾ªç¯ï¼ˆ1å‘¨ï¼‰
1. å®ç°å†…å¾ªç¯ï¼ˆåˆ†ç±»å™¨è®­ç»ƒï¼‰
2. å®ç°å¤–å¾ªç¯ï¼ˆæƒé‡è°ƒæ•´ï¼‰
3. é›†æˆåˆ°Curationé˜¶æ®µ

### Phase 4: ä¼˜åŒ–æ ·æœ¬åˆ†è§£ï¼ˆ1å‘¨ï¼‰
1. è®¾è®¡å¯é…ç½®çš„å­—æ®µschema
2. å®ç°ä¾èµ–åˆ†æ
3. æ”¯æŒåŠ¨æ€åˆ†ç»„

---

## ğŸ’¡ å…³é”®å¯ç¤º

### å½“å‰ä»£ç çš„å®šä½

**ä¸æ˜¯**ï¼šä¸¥æ ¼æŒ‰ç…§DGMè®ºæ–‡å®ç°çš„å­¦æœ¯ä»£ç 
**è€Œæ˜¯**ï¼šå—DGMå¯å‘çš„**å·¥ç¨‹å®ç”¨ç‰ˆæœ¬**

### ä¼˜ç‚¹
- âœ… åŠŸèƒ½å®Œæ•´å¯ç”¨
- âœ… ç”Ÿæˆæ•°æ®è´¨é‡é«˜ï¼ˆIndirect: 100%ï¼‰
- âœ… æ¡†æ¶ç»“æ„æ¸…æ™°

### å±€é™
- âš ï¸ ç†è®ºå®ç°ç®€åŒ–è¿‡åº¦
- âš ï¸ ç¼ºå°‘çœŸæ­£çš„MLç»„ä»¶
- âš ï¸ ç»“æ„è®¾è®¡æœ‰æŠ€æœ¯å€º

---

## ğŸ¯ å»ºè®®

### å¯¹äºç”Ÿäº§ä½¿ç”¨
å½“å‰ä»£ç **å¯ä»¥ä½¿ç”¨**ï¼Œè´¨é‡å·²ç»å¾ˆå¥½ã€‚

### å¯¹äºå­¦æœ¯ç ”ç©¶
éœ€è¦è¡¥å……çœŸæ­£çš„MLç»„ä»¶æ‰èƒ½å£°ç§°"å®Œæ•´å®ç°DGMæ¡†æ¶"ã€‚

### å¯¹äºä»£ç è´¨é‡æå‡
ä¼˜å…ˆä¿®å¤ç»“æ„é—®é¢˜ï¼ˆP0ï¼‰ï¼Œå†è€ƒè™‘MLç»„ä»¶ï¼ˆP1ï¼‰ã€‚

---

**ç‰ˆæœ¬**: 1.0  
**æ—¥æœŸ**: 2025-12-05  
**ä½œè€…**: ä»£ç å®¡æŸ¥ç»„
